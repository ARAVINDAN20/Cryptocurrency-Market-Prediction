{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install ccxt pandas numpy scikit-learn tensorflow pycoingecko\n"
      ],
      "metadata": {
        "id": "puWT9NE1jZ9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pAkxXm8njX7I"
      },
      "outputs": [],
      "source": [
        "import ccxt\n",
        "import pandas as pd\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Initialize the exchange (Kraken or Binance US)\n",
        "exchange = ccxt.kraken()  # Use 'binanceus' if needed\n",
        "\n",
        "# Create folder to store datasets\n",
        "data_folder = 'crypto_datasets'\n",
        "if not os.path.exists(data_folder):\n",
        "    os.makedirs(data_folder)\n",
        "\n",
        "# Define a function to fetch and save historical data for a symbol\n",
        "def fetch_and_save_data(symbol, timeframe='1d', since=None, limit=500):\n",
        "    try:\n",
        "        print(f\"Fetching data for {symbol}...\")\n",
        "        ohlcv = exchange.fetch_ohlcv(symbol, timeframe=timeframe, since=since, limit=limit)\n",
        "        if ohlcv:\n",
        "            df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\n",
        "            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
        "            csv_file = os.path.join(data_folder, f\"{symbol.replace('/', '_')}.csv\")\n",
        "            df.to_csv(csv_file, index=False)\n",
        "            print(f\"Data saved for {symbol} in {csv_file}\")\n",
        "        else:\n",
        "            print(f\"No data found for {symbol}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching data for {symbol}: {str(e)}\")\n",
        "\n",
        "# Fetch all available markets (symbols) from the exchange\n",
        "markets = exchange.load_markets()\n",
        "symbols = [market for market in markets if markets[market]['quote'] == 'USD']  # Filter for USD quote markets\n",
        "\n",
        "# Fetch historical data for each symbol and save it to CSV\n",
        "since = exchange.parse8601('2023-01-01T00:00:00Z')  # Fetch data since 2023\n",
        "for symbol in symbols:\n",
        "    fetch_and_save_data(symbol, since=since)\n",
        "\n",
        "print(\"Data fetching complete.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ccxt\n",
        "import pandas as pd\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Create a folder for storing the datasets\n",
        "data_folder = 'crypto_data_all'\n",
        "if not os.path.exists(data_folder):\n",
        "    os.makedirs(data_folder)\n",
        "\n",
        "# Function to fetch and save data for all symbols of an exchange\n",
        "def fetch_and_save_data(exchange):\n",
        "    markets = exchange.load_markets()  # Load all available markets\n",
        "    for symbol in markets:\n",
        "        # Only fetch data for cryptocurrencies (filter out non-crypto markets)\n",
        "        if '/' not in symbol:\n",
        "            continue  # Skip non-crypto symbols\n",
        "\n",
        "        try:\n",
        "            # Fetch OHLCV data for the last 1000 candles (adjust timeframe if needed)\n",
        "            ohlcv = exchange.fetch_ohlcv(symbol, timeframe='1d', limit=1000)\n",
        "\n",
        "            # Convert to DataFrame\n",
        "            df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\n",
        "\n",
        "            # Convert timestamp to readable datetime\n",
        "            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
        "\n",
        "            # Save to CSV\n",
        "            filename = f'{data_folder}/{exchange.id}_{symbol.replace(\"/\", \"_\")}.csv'\n",
        "            df.to_csv(filename, index=False)\n",
        "            print(f\"Saved {symbol} data to {filename}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error fetching data for {symbol}: {str(e)}\")\n",
        "\n",
        "# Initialize the exchanges\n",
        "exchanges = {\n",
        "    'kraken': ccxt.kraken(),\n",
        "    'binanceus': ccxt.binanceus()\n",
        "}\n",
        "\n",
        "# Fetch and save data for each exchange\n",
        "for exchange_name, exchange in exchanges.items():\n",
        "    print(f\"Fetching data from {exchange_name}...\")\n",
        "    fetch_and_save_data(exchange)\n",
        "\n",
        "print(\"Data fetching complete!\")\n"
      ],
      "metadata": {
        "id": "3Uibr4fijmh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ccxt\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "import logging\n",
        "from datetime import datetime\n",
        "\n",
        "# ===========================\n",
        "# Configuration Parameters\n",
        "# ===========================\n",
        "\n",
        "# List of cryptocurrency symbols\n",
        "symbols = [\n",
        "    \"1INCH/EUR\", \"1INCH/USD\", \"AAVE/ETH\", \"AAVE/EUR\", \"AAVE/GBP\", \"AAVE/USD\",\n",
        "    \"AAVE/BTC\", \"ACA/EUR\", \"ACA/USD\", \"ACH/EUR\", \"ACH/USD\", \"ADA/AUD\",\n",
        "    \"ADA/ETH\", \"ADA/EUR\", \"ADA/GBP\", \"ADA/USD\", \"ADA/USDT\", \"ADA/BTC\",\n",
        "    # ... (Include all other symbols here)\n",
        "    \"USD/CAD\", \"USD/JPY\"\n",
        "]\n",
        "\n",
        "# Exchanges to use in priority order\n",
        "exchange_priority = ['binanceus', 'kraken']\n",
        "\n",
        "# Timeframe for OHLCV data\n",
        "timeframe = '1d'  # Daily data; you can change to '1h', '1m', etc.\n",
        "\n",
        "# Number of data points to fetch\n",
        "limit = 1000  # Maximum allowed by the exchange\n",
        "\n",
        "# Folder to save CSV files\n",
        "data_folder = 'crypto_data'\n",
        "\n",
        "# Logging configuration\n",
        "log_file = 'data_fetching.log'\n",
        "logging.basicConfig(\n",
        "    filename=log_file,\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "\n",
        "# ===========================\n",
        "# Helper Functions\n",
        "# ===========================\n",
        "\n",
        "def initialize_exchanges():\n",
        "    \"\"\"\n",
        "    Initialize the exchanges and load their markets.\n",
        "    \"\"\"\n",
        "    exchanges = {}\n",
        "    for ex in exchange_priority:\n",
        "        try:\n",
        "            exchange = getattr(ccxt, ex)()\n",
        "            exchange.load_markets()\n",
        "            exchanges[ex] = exchange\n",
        "            logging.info(f\"Initialized exchange: {ex}\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error initializing exchange {ex}: {e}\")\n",
        "    return exchanges\n",
        "\n",
        "def create_data_folder(folder):\n",
        "    \"\"\"\n",
        "    Create the data folder if it doesn't exist.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(folder):\n",
        "        os.makedirs(folder)\n",
        "        logging.info(f\"Created data folder: {folder}\")\n",
        "\n",
        "def fetch_ohlcv_data(exchange, symbol, timeframe, limit):\n",
        "    \"\"\"\n",
        "    Fetch OHLCV data for a given symbol from a specific exchange.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        ohlcv = exchange.fetch_ohlcv(symbol, timeframe=timeframe, limit=limit)\n",
        "        logging.info(f\"Fetched data for {symbol} from {exchange.id}\")\n",
        "        return ohlcv\n",
        "    except Exception as e:\n",
        "        logging.warning(f\"Failed to fetch {symbol} from {exchange.id}: {e}\")\n",
        "        return None\n",
        "\n",
        "def save_to_csv(data, symbol, folder):\n",
        "    \"\"\"\n",
        "    Save the OHLCV data to a CSV file.\n",
        "    \"\"\"\n",
        "    df = pd.DataFrame(data, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
        "    # Replace '/' with '_' for filename\n",
        "    filename = symbol.replace('/', '_') + '.csv'\n",
        "    filepath = os.path.join(folder, filename)\n",
        "    df.to_csv(filepath, index=False)\n",
        "    logging.info(f\"Saved data to {filepath}\")\n",
        "\n",
        "def main():\n",
        "    # Initialize exchanges\n",
        "    exchanges = initialize_exchanges()\n",
        "\n",
        "    # Create data folder\n",
        "    create_data_folder(data_folder)\n",
        "\n",
        "    # Iterate over each symbol\n",
        "    for symbol in symbols:\n",
        "        logging.info(f\"Processing symbol: {symbol}\")\n",
        "        data_fetched = False\n",
        "\n",
        "        for ex_id in exchange_priority:\n",
        "            exchange = exchanges.get(ex_id)\n",
        "            if exchange is None:\n",
        "                continue\n",
        "\n",
        "            # Check if the symbol exists on the exchange\n",
        "            if symbol in exchange.symbols:\n",
        "                logging.info(f\"{symbol} found on {ex_id}\")\n",
        "                ohlcv = fetch_ohlcv_data(exchange, symbol, timeframe, limit)\n",
        "                if ohlcv:\n",
        "                    save_to_csv(ohlcv, symbol, data_folder)\n",
        "                    data_fetched = True\n",
        "                    # Respect rate limits\n",
        "                    time.sleep(exchange.rateLimit / 1000)\n",
        "                    break\n",
        "            else:\n",
        "                logging.info(f\"{symbol} not available on {ex_id}\")\n",
        "\n",
        "        if not data_fetched:\n",
        "            logging.error(f\"{symbol} not found on any supported exchanges.\")\n",
        "\n",
        "    logging.info(\"Data fetching process completed.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    start_time = datetime.now()\n",
        "    logging.info(\"Data fetching script started.\")\n",
        "    main()\n",
        "    end_time = datetime.now()\n",
        "    duration = end_time - start_time\n",
        "    logging.info(f\"Script finished. Duration: {duration}\")\n"
      ],
      "metadata": {
        "id": "pVc-L0X0lwpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ccxt\n",
        "import os\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Initialize the exchange (Kraken or Binance US)\n",
        "kraken = ccxt.kraken()\n",
        "binance_us = ccxt.binanceus()\n",
        "\n",
        "# Create a folder to store the data\n",
        "data_folder = 'crypto_data_Current data'\n",
        "if not os.path.exists(data_folder):\n",
        "    os.makedirs(data_folder)\n",
        "\n",
        "# Function to save OHLCV data to CSV\n",
        "def save_data_to_csv(exchange, symbol, since, timeframe='1d'):\n",
        "    try:\n",
        "        # Fetch historical data (OHLCV: Open, High, Low, Close, Volume)\n",
        "        ohlcv_data = exchange.fetch_ohlcv(symbol, timeframe, since=since)\n",
        "        if ohlcv_data:\n",
        "            # Convert to DataFrame\n",
        "            df = pd.DataFrame(ohlcv_data, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\n",
        "            # Convert timestamp to readable date\n",
        "            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
        "\n",
        "            # Generate file name for CSV\n",
        "            file_name = f\"{symbol.replace('/', '-')}.csv\"\n",
        "            file_path = os.path.join(data_folder, file_name)\n",
        "\n",
        "            # Save DataFrame to CSV\n",
        "            df.to_csv(file_path, index=False)\n",
        "            print(f\"Saved data for {symbol} to {file_path}\")\n",
        "        else:\n",
        "            print(f\"No data available for {symbol}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching data for {symbol}: {e}\")\n",
        "\n",
        "# Function to get crypto symbols (excluding fiat pairs)\n",
        "def get_crypto_symbols(exchange):\n",
        "    symbols = []\n",
        "    markets = exchange.load_markets()\n",
        "    for market in markets:\n",
        "        if '/' in market:\n",
        "            base, quote = market.split('/')\n",
        "            # Filter out fiat currencies like USD, EUR, etc.\n",
        "            if quote not in ['USD', 'EUR', 'JPY', 'GBP', 'AUD', 'CAD', 'CHF']:\n",
        "                symbols.append(market)\n",
        "    return symbols\n",
        "\n",
        "# Set the timeframe and 'since' date for historical data (fetch past 1 year of data)\n",
        "timeframe = '1d'  # Daily OHLCV data\n",
        "since = exchange.parse8601('2023-01-01T00:00:00Z')  # You can modify this to get more historical data\n",
        "\n",
        "# Fetch and save data for Kraken\n",
        "print(\"Fetching data from Kraken...\")\n",
        "kraken_symbols = get_crypto_symbols(kraken)\n",
        "for symbol in kraken_symbols:\n",
        "    save_data_to_csv(kraken, symbol, since, timeframe)\n",
        "\n",
        "# Fetch and save data for Binance US\n",
        "print(\"Fetching data from Binance US...\")\n",
        "binance_us_symbols = get_crypto_symbols(binance_us)\n",
        "for symbol in binance_us_symbols:\n",
        "    save_data_to_csv(binance_us, symbol, since, timeframe)\n",
        "\n",
        "print(\"Data extraction complete.\")\n"
      ],
      "metadata": {
        "id": "tj-nn3oZlx-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To generate and extract cryptocurrency market data for all available symbols from Kraken and Binance US using the `ccxt` library and save them into CSV files, we will follow the steps outlined below:\n",
        "\n",
        "### Process Outline:\n",
        "1. **Initialize the exchange**: Connect to Kraken or Binance US using the `ccxt` library.\n",
        "2. **Retrieve available symbols**: Fetch all available trading symbols for cryptocurrency pairs (we will skip fiat pairs like EUR/USD).\n",
        "3. **Fetch historical data**: Extract OHLCV (Open, High, Low, Close, Volume) data for each symbol, capturing as much data as the exchange allows.\n",
        "4. **Save data to CSV**: For each symbol, save the historical data to a CSV file.\n",
        "5. **Organize datasets**: Store the data in a structured folder for further model building.\n",
        "\n",
        "### Full Code Implementation:\n",
        "\n",
        "```python\n",
        "import ccxt\n",
        "import os\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Initialize the exchange (Kraken or Binance US)\n",
        "kraken = ccxt.kraken()\n",
        "binance_us = ccxt.binanceus()\n",
        "\n",
        "# Create a folder to store the data\n",
        "data_folder = 'crypto_data'\n",
        "if not os.path.exists(data_folder):\n",
        "    os.makedirs(data_folder)\n",
        "\n",
        "# Function to save OHLCV data to CSV\n",
        "def save_data_to_csv(exchange, symbol, since, timeframe='1d'):\n",
        "    try:\n",
        "        # Fetch historical data (OHLCV: Open, High, Low, Close, Volume)\n",
        "        ohlcv_data = exchange.fetch_ohlcv(symbol, timeframe, since=since)\n",
        "        if ohlcv_data:\n",
        "            # Convert to DataFrame\n",
        "            df = pd.DataFrame(ohlcv_data, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\n",
        "            # Convert timestamp to readable date\n",
        "            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
        "            \n",
        "            # Generate file name for CSV\n",
        "            file_name = f\"{symbol.replace('/', '-')}.csv\"\n",
        "            file_path = os.path.join(data_folder, file_name)\n",
        "            \n",
        "            # Save DataFrame to CSV\n",
        "            df.to_csv(file_path, index=False)\n",
        "            print(f\"Saved data for {symbol} to {file_path}\")\n",
        "        else:\n",
        "            print(f\"No data available for {symbol}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching data for {symbol}: {e}\")\n",
        "\n",
        "# Function to get crypto symbols (excluding fiat pairs)\n",
        "def get_crypto_symbols(exchange):\n",
        "    symbols = []\n",
        "    markets = exchange.load_markets()\n",
        "    for market in markets:\n",
        "        if '/' in market:\n",
        "            base, quote = market.split('/')\n",
        "            # Filter out fiat currencies like USD, EUR, etc.\n",
        "            if quote not in ['USD', 'EUR', 'JPY', 'GBP', 'AUD', 'CAD', 'CHF']:\n",
        "                symbols.append(market)\n",
        "    return symbols\n",
        "\n",
        "# Set the timeframe and 'since' date for historical data (fetch past 1 year of data)\n",
        "timeframe = '1d'  # Daily OHLCV data\n",
        "since = exchange.parse8601('2023-01-01T00:00:00Z')  # You can modify this to get more historical data\n",
        "\n",
        "# Fetch and save data for Kraken\n",
        "print(\"Fetching data from Kraken...\")\n",
        "kraken_symbols = get_crypto_symbols(kraken)\n",
        "for symbol in kraken_symbols:\n",
        "    save_data_to_csv(kraken, symbol, since, timeframe)\n",
        "\n",
        "# Fetch and save data for Binance US\n",
        "print(\"Fetching data from Binance US...\")\n",
        "binance_us_symbols = get_crypto_symbols(binance_us)\n",
        "for symbol in binance_us_symbols:\n",
        "    save_data_to_csv(binance_us, symbol, since, timeframe)\n",
        "\n",
        "print(\"Data extraction complete.\")\n",
        "```\n",
        "\n",
        "### Detailed Explanation:\n",
        "1. **Exchange Initialization**:\n",
        "   - We initialize two exchanges: Kraken (`ccxt.kraken()`) and Binance US (`ccxt.binanceus()`).\n",
        "  \n",
        "2. **Folder Creation**:\n",
        "   - A folder named `crypto_data` is created to store the CSV files for each cryptocurrency symbol.\n",
        "\n",
        "3. **Fetching Symbols**:\n",
        "   - The `get_crypto_symbols()` function filters out non-cryptocurrency symbols by excluding pairs with fiat currencies (USD, EUR, etc.).\n",
        "\n",
        "4. **Data Fetching**:\n",
        "   - The `fetch_ohlcv()` function is used to retrieve historical OHLCV data (Open, High, Low, Close, Volume) for each symbol.\n",
        "   - Data is fetched for the daily (`1d`) timeframe since January 1, 2023, but you can modify this range to get more data as needed.\n",
        "\n",
        "5. **Data Saving**:\n",
        "   - The retrieved data is stored in a CSV file with the symbol name as the file name (e.g., `BTC-USDT.csv`).\n",
        "   - Each file is saved in the `crypto_data` folder.\n",
        "\n",
        "6. **Error Handling**:\n",
        "   - The code includes error handling to catch any issues with data fetching or symbol errors.\n",
        "\n",
        "### How It Works:\n",
        "1. The script connects to both Kraken and Binance US exchanges and loads all available markets (symbols).\n",
        "2. It then filters the symbols to only keep cryptocurrency pairs, excluding fiat currency pairs.\n",
        "3. For each symbol, it fetches OHLCV data (historical price and volume) and saves it in a CSV file.\n",
        "4. The data for each cryptocurrency symbol is saved in a structured folder, which can later be used for model training.\n",
        "\n",
        "This script ensures you extract as much historical data as possible for each cryptocurrency supported by the exchange, and you can later use this data for price prediction models."
      ],
      "metadata": {
        "id": "_Et7XJLXn97g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ccxt pandas numpy matplotlib seaborn scikit-learn tensorflow\n"
      ],
      "metadata": {
        "id": "Iu9szyW-sLMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "# !pip install ccxt pandas numpy matplotlib seaborn scikit-learn tensorflow\n",
        "\n",
        "import ccxt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# Step 1: Data Gathering from Kraken (using BTC/USD pair)\n",
        "def fetch_ohlcv_data(symbol, timeframe='1d', since=None):\n",
        "    exchange = ccxt.kraken()  # or ccxt.binanceus()\n",
        "    ohlcv_data = exchange.fetch_ohlcv(symbol, timeframe=timeframe, since=since)\n",
        "    # Convert to DataFrame\n",
        "    df = pd.DataFrame(ohlcv_data, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
        "    return df\n",
        "\n",
        "# Fetch historical data for BTC/USD\n",
        "data = fetch_ohlcv_data('BTC/USD')\n",
        "\n",
        "# Step 2: Data Preprocessing\n",
        "# Sort by timestamp\n",
        "data = data.sort_values('timestamp')\n",
        "\n",
        "# Normalize the 'close' price\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "data['scaled_close'] = scaler.fit_transform(data['close'].values.reshape(-1,1))\n",
        "\n",
        "# Prepare the training data (last 60 days to predict the next day)\n",
        "def create_dataset(data, time_step=60):\n",
        "    X, y = [], []\n",
        "    for i in range(time_step, len(data)):\n",
        "        X.append(data[i-time_step:i, 0])\n",
        "        y.append(data[i, 0])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Prepare the dataset\n",
        "scaled_data = data['scaled_close'].values.reshape(-1, 1)\n",
        "X, y = create_dataset(scaled_data)\n",
        "\n",
        "# Reshape for LSTM input (samples, timesteps, features)\n",
        "X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
        "\n",
        "# Split into train and test sets\n",
        "split_ratio = 0.8\n",
        "split = int(len(X) * split_ratio)\n",
        "X_train, X_test = X[:split], X[split:]\n",
        "y_train, y_test = y[:split], y[split:]\n",
        "\n",
        "# Step 3: Building the LSTM Model\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(units=50, return_sequences=False))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=1))  # Predict the 'close' price\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Step 4: Training the Model\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Step 5: Testing the Model and Visualizing the Results\n",
        "predicted_prices = model.predict(X_test)\n",
        "predicted_prices = scaler.inverse_transform(predicted_prices)\n",
        "\n",
        "# Unscale the real test values\n",
        "real_prices = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
        "\n",
        "# Visualize the results\n",
        "plt.figure(figsize=(14, 5))\n",
        "plt.plot(real_prices, color='blue', label='Actual BTC/USD Price')\n",
        "plt.plot(predicted_prices, color='red', label='Predicted BTC/USD Price')\n",
        "plt.title('BTC/USD Price Prediction')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Price')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Step 6: Model Accuracy (MSE, RMSE)\n",
        "mse = mean_squared_error(real_prices, predicted_prices)\n",
        "rmse = np.sqrt(mse)\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "print(f'Root Mean Squared Error: {rmse}')\n",
        "\n"
      ],
      "metadata": {
        "id": "A6s_JoNCn-5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# Step 1: Make Predictions\n",
        "predicted_prices = model.predict(X_test)\n",
        "predicted_prices = scaler.inverse_transform(predicted_prices)  # Unscale predicted prices\n",
        "real_prices = scaler.inverse_transform(y_test.reshape(-1, 1))  # Unscale actual prices\n",
        "\n",
        "# Step 2: Calculate the Accuracy Metrics\n",
        "# Mean Squared Error (MSE)\n",
        "mse = mean_squared_error(real_prices, predicted_prices)\n",
        "\n",
        "# Root Mean Squared Error (RMSE)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "# Mean Absolute Error (MAE)\n",
        "mae = mean_absolute_error(real_prices, predicted_prices)\n",
        "\n",
        "# R-squared (R²) Score\n",
        "r2 = r2_score(real_prices, predicted_prices)\n",
        "\n",
        "# Step 3: Print the Accuracy Metrics\n",
        "print(f\"Mean Squared Error (MSE): {mse}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
        "print(f\"R-squared (R²) Score: {r2}\")\n"
      ],
      "metadata": {
        "id": "qUWRqQV0sRP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import ccxt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# Fetch OHLCV Data from Kraken or Binance US\n",
        "def fetch_ohlcv_data(symbol, timeframe='1d', since=None):\n",
        "    exchange = ccxt.kraken()  # Change to binanceus() if needed\n",
        "    ohlcv_data = exchange.fetch_ohlcv(symbol, timeframe=timeframe, since=since)\n",
        "    df = pd.DataFrame(ohlcv_data, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
        "    return df\n",
        "\n",
        "# Fetch historical data for BTC/USD\n",
        "data = fetch_ohlcv_data('BTC/USD')\n",
        "\n",
        "# Data Preprocessing\n",
        "data = data.sort_values('timestamp')\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "data['scaled_close'] = scaler.fit_transform(data['close'].values.reshape(-1,1))\n",
        "\n",
        "# Prepare the data\n",
        "def create_dataset(data, time_step=60):\n",
        "    X, y = [], []\n",
        "    for i in range(time_step, len(data)):\n",
        "        X.append(data[i-time_step:i, 0])\n",
        "        y.append(data[i, 0])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "scaled_data = data['scaled_close'].values.reshape(-1, 1)\n",
        "X, y = create_dataset(scaled_data)\n",
        "\n",
        "X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
        "\n",
        "split_ratio = 0.8\n",
        "split = int(len(X) * split_ratio)\n",
        "X_train, X_test = X[:split], X[split:]\n",
        "y_train, y_test = y[:split], y[split:]\n",
        "\n",
        "# Building the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(units=50, return_sequences=False))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=1))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Make predictions\n",
        "predicted_prices = model.predict(X_test)\n",
        "predicted_prices = scaler.inverse_transform(predicted_prices)\n",
        "\n",
        "real_prices = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
        "\n",
        "# Visualization of predicted vs actual prices\n",
        "plt.figure(figsize=(14, 5))\n",
        "plt.plot(real_prices, color='blue', label='Actual BTC/USD Price')\n",
        "plt.plot(predicted_prices, color='red', label='Predicted BTC/USD Price')\n",
        "plt.title('BTC/USD Price Prediction')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Price')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Accuracy Metrics\n",
        "mse = mean_squared_error(real_prices, predicted_prices)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(real_prices, predicted_prices)\n",
        "explained_var = explained_variance_score(real_prices, predicted_prices)\n",
        "\n",
        "# Printing accuracy metrics\n",
        "print(f'Mean Squared Error (MSE): {mse}')\n",
        "print(f'Root Mean Squared Error (RMSE): {rmse}')\n",
        "print(f'Mean Absolute Error (MAE): {mae}')\n",
        "print(f'Explained Variance Score: {explained_var * 100}%')\n",
        "\n",
        "# Let's assume the \"accuracy\" as the complement of the normalized RMSE\n",
        "accuracy = 100 - (rmse / np.mean(real_prices)) * 100\n",
        "print(f'Model Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "# Heatmap of error distribution\n",
        "errors = real_prices - predicted_prices\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.heatmap(errors, annot=False, cmap=\"coolwarm\")\n",
        "plt.title('Error Distribution Heatmap')\n",
        "plt.show()\n",
        "\n",
        "# Confusion Matrix-like visualization for regression (only for reference, not typical in regression)\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.scatter(real_prices, predicted_prices, c='blue')\n",
        "plt.plot(real_prices, real_prices, color='red', linewidth=2)\n",
        "plt.title('Actual vs Predicted Prices')\n",
        "plt.xlabel('Actual Prices')\n",
        "plt.ylabel('Predicted Prices')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "x7DOFbdXtFhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Generate the code to display the accuracy of this model like print the accuracy of this model\n",
        "\n",
        "# Calculate the Accuracy Metrics\n",
        "# Mean Squared Error (MSE)\n",
        "mse = mean_squared_error(real_prices, predicted_prices)\n",
        "\n",
        "# Root Mean Squared Error (RMSE)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "# Mean Absolute Error (MAE)\n",
        "mae = mean_absolute_error(real_prices, predicted_prices)\n",
        "\n",
        "# R-squared (R²) Score\n",
        "r2 = r2_score(real_prices, predicted_prices)\n",
        "\n",
        "# Print the Accuracy Metrics\n",
        "print(f\"Mean Squared Error (MSE): {mse}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
        "print(f\"R-squared (R²) Score: {r2}\")\n"
      ],
      "metadata": {
        "id": "fbB53bBStZ9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Only I need accuracy in percentage how much it is predicted correctly\n",
        "\n",
        "# Calculate the Accuracy Metrics\n",
        "# Mean Squared Error (MSE)\n",
        "mse = mean_squared_error(real_prices, predicted_prices)\n",
        "\n",
        "# Root Mean Squared Error (RMSE)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "# Let's assume the \"accuracy\" as the complement of the normalized RMSE\n",
        "accuracy = 100 - (rmse / np.mean(real_prices)) * 100\n",
        "print(f'Model Accuracy: {accuracy:.2f}%')\n"
      ],
      "metadata": {
        "id": "MuBH1LT4tsxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import ccxt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# Fetch OHLCV Data from Kraken or Binance US\n",
        "def fetch_ohlcv_data(symbol, timeframe='1d', since=None):\n",
        "    exchange = ccxt.kraken()  # Change to binanceus() if needed\n",
        "    ohlcv_data = exchange.fetch_ohlcv(symbol, timeframe=timeframe, since=since)\n",
        "    df = pd.DataFrame(ohlcv_data, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
        "    return df\n",
        "\n",
        "# Fetch historical data for BTC/USD\n",
        "data = fetch_ohlcv_data('XMR/USDT')\n",
        "\n",
        "# Data Preprocessing\n",
        "data = data.sort_values('timestamp')\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "data['scaled_close'] = scaler.fit_transform(data['close'].values.reshape(-1,1))\n",
        "\n",
        "# Prepare the data\n",
        "def create_dataset(data, time_step=60):\n",
        "    X, y = [], []\n",
        "    for i in range(time_step, len(data)):\n",
        "        X.append(data[i-time_step:i, 0])\n",
        "        y.append(data[i, 0])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "scaled_data = data['scaled_close'].values.reshape(-1, 1)\n",
        "X, y = create_dataset(scaled_data)\n",
        "\n",
        "X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
        "\n",
        "split_ratio = 0.8\n",
        "split = int(len(X) * split_ratio)\n",
        "X_train, X_test = X[:split], X[split:]\n",
        "y_train, y_test = y[:split], y[split:]\n",
        "\n",
        "# Building the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(units=50, return_sequences=False))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=1))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Make predictions\n",
        "predicted_prices = model.predict(X_test)\n",
        "predicted_prices = scaler.inverse_transform(predicted_prices)\n",
        "\n",
        "real_prices = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
        "\n",
        "# Visualization of predicted vs actual prices\n",
        "plt.figure(figsize=(14, 5))\n",
        "plt.plot(real_prices, color='blue', label='Actual BTC/USD Price')\n",
        "plt.plot(predicted_prices, color='red', label='Predicted BTC/USD Price')\n",
        "plt.title('XMR/USDT Price Prediction')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Price')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Accuracy Metrics\n",
        "mse = mean_squared_error(real_prices, predicted_prices)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(real_prices, predicted_prices)\n",
        "explained_var = explained_variance_score(real_prices, predicted_prices)\n",
        "\n",
        "# Printing accuracy metrics\n",
        "print(f'Mean Squared Error (MSE): {mse}')\n",
        "print(f'Root Mean Squared Error (RMSE): {rmse}')\n",
        "print(f'Mean Absolute Error (MAE): {mae}')\n",
        "print(f'Explained Variance Score: {explained_var * 100}%')\n",
        "\n",
        "# Let's assume the \"accuracy\" as the complement of the normalized RMSE\n",
        "accuracy = 100 - (rmse / np.mean(real_prices)) * 100\n",
        "print(f'Model Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "# Heatmap of error distribution\n",
        "errors = real_prices - predicted_prices\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.heatmap(errors, annot=False, cmap=\"coolwarm\")\n",
        "plt.title('Error Distribution Heatmap')\n",
        "plt.show()\n",
        "\n",
        "# Confusion Matrix-like visualization for regression (only for reference, not typical in regression)\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.scatter(real_prices, predicted_prices, c='blue')\n",
        "plt.plot(real_prices, real_prices, color='red', linewidth=2)\n",
        "plt.title('Actual vs Predicted Prices')\n",
        "plt.xlabel('Actual Prices')\n",
        "plt.ylabel('Predicted Prices')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "iUMNtcPptyY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Calculate the Accuracy Metrics\n",
        "# Mean Squared Error (MSE)\n",
        "mse = mean_squared_error(real_prices, predicted_prices)\n",
        "\n",
        "# Root Mean Squared Error (RMSE)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "# Mean Absolute Error (MAE)\n",
        "mae = mean_absolute_error(real_prices, predicted_prices)\n",
        "\n",
        "# R-squared (R²) Score\n",
        "r2 = r2_score(real_prices, predicted_prices)\n",
        "\n",
        "# Print the Accuracy Metrics\n",
        "print(f\"Mean Squared Error (MSE): {mse}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
        "print(f\"R-squared (R²) Score: {r2}\")\n"
      ],
      "metadata": {
        "id": "G2Kefcvjw64i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Only I need accuracy in percentage how much it is predicted correctly\n",
        "\n",
        "# Calculate the Accuracy Metrics\n",
        "# Mean Squared Error (MSE)\n",
        "mse = mean_squared_error(real_prices, predicted_prices)\n",
        "\n",
        "# Root Mean Squared Error (RMSE)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "# Let's assume the \"accuracy\" as the complement of the normalized RMSE\n",
        "accuracy = 100 - (rmse / np.mean(real_prices)) * 100\n",
        "print(f'Model Accuracy: {accuracy:.2f}%')\n"
      ],
      "metadata": {
        "id": "6T3joFQNw9eR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4qCskYqUxNOs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}